{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vYadQfkXkuB5",
    "outputId": "21eaaa0f-0b64-47f7-a95d-4d95c9ee18af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/donors-choose/preprocessed_data.csv\n",
      "/kaggle/input/glove6b100dtxt/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "O6sC7S7mkuCH"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FeglN1-kuCS",
    "outputId": "2f60e58c-9c48-42c8-b0b4-fe69aa1a5bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFAZwvDUkuCb"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('/kaggle/input/donors-choose/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3i4T_0hkuCz"
   },
   "outputs": [],
   "source": [
    "y=data['project_is_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjTrTXiFkuC5"
   },
   "outputs": [],
   "source": [
    "data=data.drop(['project_is_approved'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzV6zxPhkuDC"
   },
   "outputs": [],
   "source": [
    "preproc=[]\n",
    "for row in data['project_grade_category']:\n",
    "    row=row.replace('grades','')\n",
    "    row=row.replace('_prek_2','prek2')\n",
    "    row=row.replace('_3_5','3to5')\n",
    "    row=row.replace('_6_8','6to8')\n",
    "    row=row.replace('_9_12','9to12')\n",
    "    preproc.append(row)\n",
    "    \n",
    "data['project_grade_category']=preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuYDGk1BkuDO"
   },
   "outputs": [],
   "source": [
    "preproc=[]\n",
    "for row in data['clean_categories']:\n",
    "    row=row.replace(' ','')\n",
    "    row=row.replace('_','')\n",
    "    preproc.append(row)\n",
    "    \n",
    "data['clean_categories']=preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbLka2cJkuDX"
   },
   "outputs": [],
   "source": [
    "preproc=[]\n",
    "for row in data['clean_subcategories']:\n",
    "    row=row.replace(' ','')\n",
    "    row=row.replace('_','')\n",
    "    preproc.append(row)\n",
    "    \n",
    "data['clean_subcategories']=preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvFAq_3IkuDg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY00SMMqkuDl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-wo3BNwkuDq",
    "outputId": "ce9268ac-c48a-4ba1-85f5-b3da4167b9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'clean_categories',\n",
       "       'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W48slF1fkuDv",
    "outputId": "8341250e-f9ea-4124-cdcf-992ab6a71e99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM,Input,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wuV-X1akuD1"
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kQ7MT54kuD2"
   },
   "source": [
    "### Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGLTtM1gkuD3"
   },
   "outputs": [],
   "source": [
    "#credit to https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(X_train['essay'])\n",
    "vocabulary_size = len(token.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3eB4H5TkuD8"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, i in token.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TVp3FFYkuEB"
   },
   "outputs": [],
   "source": [
    "word_count = []\n",
    "\n",
    "for e in data[\"essay\"] :\n",
    "    c = len(e.split())\n",
    "    word_count.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF6j3skvkuEH"
   },
   "outputs": [],
   "source": [
    "max_word_count=max(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQ8c5VeikuEM",
    "outputId": "3c07047f-6efd-49de-d2c3-93355b7009c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0SGZI0MkuER"
   },
   "outputs": [],
   "source": [
    "train_essay=token.texts_to_sequences(X_train['essay'])\n",
    "test_essay=token.texts_to_sequences(X_test['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txEySF6rkuEY"
   },
   "outputs": [],
   "source": [
    "train_essay=pad_sequences(train_essay,maxlen=350)\n",
    "test_essay=pad_sequences(test_essay,maxlen=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-1QpR6AkuEb",
    "outputId": "b7e22d89-0725-4560-bcf9-7ee3e0790107"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48181, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8lXS3Z6kuEh"
   },
   "outputs": [],
   "source": [
    "max_length=350\n",
    "input_essay = Input(shape=(max_length,))\n",
    "embedding = Embedding(vocabulary_size, 100,weights=[embedding_matrix], input_length=max_length,trainable=False)(input_essay)\n",
    "lstm=LSTM(100,return_sequences=True)(embedding)\n",
    "flatten=Flatten()(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JEj3dCg1kuFl"
   },
   "source": [
    "### Remaining Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_dzIOfQkuFn"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "train_price=X_train['price'].values.reshape(-1, 1)\n",
    "train_number=X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)\n",
    "\n",
    "test_price=X_test['price'].values.reshape(-1, 1)\n",
    "test_number=X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1)\n",
    "\n",
    "rem_train=np.concatenate((train_price,train_number),axis=1)\n",
    "rem_test=np.concatenate((test_price,test_number),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXDRcQhWkuFr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(rem_train)\n",
    "rem_train_standard=scaler.transform(rem_train)\n",
    "rem_test_standard=scaler.transform(rem_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7AS8nofkuFu"
   },
   "outputs": [],
   "source": [
    "rem_feat = Input(shape=(2,))\n",
    "rem_feat_dense= Dense(128, activation='relu')(rem_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HABJxH7GkuHV"
   },
   "source": [
    "## One Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-SlB5DI4kuHX"
   },
   "source": [
    "### School State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnrIh11hkuHY"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kelxO_IGkuHa"
   },
   "outputs": [],
   "source": [
    "my_counter=Counter()\n",
    "for word in data['school_state'].values:\n",
    "    my_counter.update(word.split())\n",
    "vocab_dict=dict(my_counter)\n",
    "sorted_vocab_dict=dict(sorted(vocab_dict.items(),key=lambda kv:kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDk7U5FrkuHd",
    "outputId": "ba390174-2564-4af5-867f-49f861d54186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None,\n",
       "                vocabulary=['vt', 'wy', 'nd', 'mt', 'ri', 'sd', 'ne', 'de',\n",
       "                            'ak', 'nh', 'wv', 'me', 'hi', 'dc', 'nm', 'ks',\n",
       "                            'ia', 'id', 'ar', 'co', 'mn', 'or', 'ky', 'ms',\n",
       "                            'nv', 'md', 'ct', 'tn', 'ut', 'al', ...])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(vocabulary=list(sorted_vocab_dict.keys()),lowercase=False,binary=True)\n",
    "vectorizer.fit(X_train['school_state'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0XRPvSJkuHg"
   },
   "outputs": [],
   "source": [
    "train_state_ohe=vectorizer.transform(X_train['school_state'].values)\n",
    "test_state_ohe=vectorizer.transform(X_test['school_state'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uj-0ttWzkuHj"
   },
   "source": [
    "### Project Grade Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VC1s8T7kuHj"
   },
   "outputs": [],
   "source": [
    "my_counter=Counter()\n",
    "for word in data['project_grade_category'].values:\n",
    "    my_counter.update(word.split())\n",
    "vocab_dict=dict(my_counter)\n",
    "sorted_vocab_dict=dict(sorted(vocab_dict.items(),key=lambda kv:kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9EqQkj9kuHq"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(vocabulary=list(sorted_vocab_dict.keys()),lowercase=False,binary=True)\n",
    "vectorizer.fit(X_train['project_grade_category'].values)\n",
    "train_grade_ohe=vectorizer.transform(X_train['project_grade_category'].values)\n",
    "test_grade_ohe=vectorizer.transform(X_test['project_grade_category'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDRvGoZskuHt"
   },
   "source": [
    "### Clean Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZwOw4oQkuHt"
   },
   "outputs": [],
   "source": [
    "my_counter=Counter()\n",
    "for word in data['clean_categories'].values:\n",
    "    my_counter.update(word.split())\n",
    "vocab_dict=dict(my_counter)\n",
    "sorted_vocab_dict=dict(sorted(vocab_dict.items(),key=lambda kv:kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hz3wwhjVkuH6"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(vocabulary=list(sorted_vocab_dict.keys()),lowercase=False,binary=True)\n",
    "vectorizer.fit(X_train['clean_categories'].values)\n",
    "train_cat_ohe=vectorizer.transform(X_train['clean_categories'].values)\n",
    "test_cat_ohe=vectorizer.transform(X_test['clean_categories'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfvsgX8ikuH9"
   },
   "source": [
    "### Clean Subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RY41KQVQkuH_"
   },
   "outputs": [],
   "source": [
    "my_counter=Counter()\n",
    "for word in data['clean_subcategories'].values:\n",
    "    my_counter.update(word.split())\n",
    "vocab_dict=dict(my_counter)\n",
    "sorted_vocab_dict=dict(sorted(vocab_dict.items(),key=lambda kv:kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rNZ8k8LkuIC"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(vocabulary=list(sorted_vocab_dict.keys()),lowercase=False,binary=True)\n",
    "vectorizer.fit(X_train['clean_subcategories'].values)\n",
    "train_sub_ohe=vectorizer.transform(X_train['clean_subcategories'].values)\n",
    "test_sub_ohe=vectorizer.transform(X_test['clean_subcategories'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LfDf0FNykuII"
   },
   "source": [
    "### Teacher Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22fZ5oygkuII"
   },
   "outputs": [],
   "source": [
    "my_counter=Counter()\n",
    "for word in data['teacher_prefix'].values:\n",
    "    my_counter.update(word.split())\n",
    "vocab_dict=dict(my_counter)\n",
    "sorted_vocab_dict=dict(sorted(vocab_dict.items(),key=lambda kv:kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2izsZNHbkuIL"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(vocabulary=list(sorted_vocab_dict.keys()),lowercase=False,binary=True)\n",
    "vectorizer.fit(X_train['teacher_prefix'].values)\n",
    "train_prefix_ohe=vectorizer.transform(X_train['teacher_prefix'].values)\n",
    "test_prefix_ohe=vectorizer.transform(X_test['teacher_prefix'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ydg6Y4UvkuIM"
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7pIkQFekuIO"
   },
   "outputs": [],
   "source": [
    "train_data=scipy.sparse.hstack((train_state_ohe,train_grade_ohe,train_cat_ohe,train_sub_ohe,train_prefix_ohe,rem_train_standard)).tocsr().todense()\n",
    "test_data=scipy.sparse.hstack(((test_state_ohe),(test_grade_ohe),(test_cat_ohe),(test_sub_ohe),(test_prefix_ohe),(rem_test_standard))).tocsr().todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6x8D91kkuIQ"
   },
   "outputs": [],
   "source": [
    "train_data=np.expand_dims(train_data, axis=2)\n",
    "test_data=np.expand_dims(test_data, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pranaya-mathur/Donors-Choose-LSTM/blob/master/DonorsChoose_Model_1_13_Aug_19.ipynb\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc_score(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "def auc_sc(y_true, y_pred):\n",
    "    return tf.py_func(auc_score, (y_true, y_pred), tf.double)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train=np_utils.to_categorical(y_train)\n",
    "Y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBkzwPlVkuIX"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D,Dropout,concatenate\n",
    "\n",
    "input_conv =  Input(shape=(train_data.shape[1],1))\n",
    "Layer1=Conv1D(filters=96,kernel_size=3,activation='relu')(input_conv)\n",
    "Layer2=MaxPooling1D(3,padding='same')(Layer1)\n",
    "Layer3=Dropout(0.5)(Layer2)\n",
    "\n",
    "Layer4=Conv1D(filters=128,kernel_size=3,activation='relu',padding='same')(Layer3)\n",
    "Layer5=MaxPooling1D(3,padding='same')(Layer4)\n",
    "Layer6=Dropout(0.5)(Layer5)\n",
    "\n",
    "Layer7=Flatten()(Layer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CM1rfziKkuIa"
   },
   "outputs": [],
   "source": [
    "concat = concatenate([flatten,Layer7])\n",
    "\n",
    "Layer8 = Dense(456, activation='relu',kernel_initializer=he_normal())(concat)\n",
    "Layer9=Dropout(0.5)(Layer8)\n",
    "\n",
    "Layer10= Dense(256, activation='relu',kernel_initializer=he_normal())(Layer9)\n",
    "Layer11=Dropout(0.5)(Layer10)\n",
    "\n",
    "Layer12 = Dense(128, activation='relu',kernel_initializer=he_normal())(Layer11)\n",
    "Layer13=BatchNormalization()(Layer12)\n",
    "\n",
    "main_output1 = Dense(2, activation='softmax')(Layer13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eesbLwe1kuIb"
   },
   "outputs": [],
   "source": [
    "model3 = Model(inputs=[input_essay,input_conv], outputs=[main_output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w92WSHyTkuIe",
    "outputId": "9096d5b1-3905-47ce-e5dc-8c6fa470d466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 514, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 512, 96)      384         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 171, 96)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 171, 96)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 350)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 171, 128)     36992       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 350, 100)     4818100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 57, 128)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 350, 100)     80400       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 57, 128)      0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 35000)        0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 7296)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 42296)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 456)          19287432    concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 456)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 256)          116992      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          32896       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            258         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 24,373,966\n",
      "Trainable params: 19,555,610\n",
      "Non-trainable params: 4,818,356\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard,EarlyStopping\n",
    "from time import time\n",
    "\n",
    "earlystop_1 = EarlyStopping(monitor = 'val_loss', mode=\"max\",min_delta = 0, patience = 4,verbose = 1,restore_best_weights = True)\n",
    "tensorboard_1 = TensorBoard(\"logs3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VG2aKW5ekuIg"
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=[auc_sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hgm7VLl1kuIg"
   },
   "outputs": [],
   "source": [
    "train_data3=[train_essay,train_data]\n",
    "test_data3=[test_essay,test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vA_thvWqkuIj",
    "outputId": "b0018070-2ca5-4cbf-8460-17883620b2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73196 samples, validate on 36052 samples\n",
      "Epoch 1/8\n",
      "73196/73196 [==============================] - 470s 6ms/step - loss: 0.4393 - auc_sc: 0.6031 - val_loss: 0.4122 - val_auc_sc: 0.7138\n",
      "Epoch 2/8\n",
      "73196/73196 [==============================] - 466s 6ms/step - loss: 0.3863 - auc_sc: 0.7175 - val_loss: 0.3777 - val_auc_sc: 0.7352\n",
      "Epoch 3/8\n",
      "73196/73196 [==============================] - 468s 6ms/step - loss: 0.3748 - auc_sc: 0.7413 - val_loss: 0.3744 - val_auc_sc: 0.7451\n",
      "Epoch 4/8\n",
      "73196/73196 [==============================] - 470s 6ms/step - loss: 0.3665 - auc_sc: 0.7574 - val_loss: 0.3750 - val_auc_sc: 0.7499\n",
      "Epoch 5/8\n",
      "73196/73196 [==============================] - 468s 6ms/step - loss: 0.3542 - auc_sc: 0.7778 - val_loss: 0.3708 - val_auc_sc: 0.7498\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6b5ae57e10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_data3,Y_train,epochs=8, batch_size=64,verbose=1,validation_data=(test_data3, Y_test),class_weight='balanced',callbacks=[tensorboard_1,earlystop_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T13:19:13.114159Z",
     "start_time": "2019-10-17T13:19:13.103716Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "PBzI39fkkuIo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+\n",
      "|  Model  | train_auc | test_auc |\n",
      "+---------+-----------+----------+\n",
      "| Model_3 |   0.7778  |  0.7498  |\n",
      "+---------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"train_auc\", \"test_auc\"]\n",
    "x.add_row([\"Model_3\", 0.7778,0.7498])\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "donors-choose-lstm(6).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
